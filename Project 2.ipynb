{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Reddit (HTML to MongoDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source Reddit\n",
    "posts = []\n",
    "url = \"http://reddit.com\"\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.122 Safari/537.36'}\n",
    "html = requests.get(url, headers=headers).text\n",
    "parser = bs(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Destination MongoDB\n",
    "client = MongoClient('mongodb://localhost:27017/')\n",
    "db = client.reddit\n",
    "db.posts.drop()\n",
    "collection = db.posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: What was the very first movie to make you cry?\n",
      "Title: Wild Karen loses mind over car on crosswalk\n",
      "Title: Texas park ranger pushed into water after reminding crowd about social distancin\n",
      "Title: I made a big flip book during quarantine. My love to everyone who is struggling \n",
      "Title: I made a really big flip book during quarantine and people said to post it here.\n",
      "Title: A guide to mattress dimensions and bed sizes\n",
      "Title: One Death Is a Tragedy. 60,000 Deaths Are a Great Success. Most presidents try t\n"
     ]
    }
   ],
   "source": [
    "# Find comments <span> element; it is the only elements all posts have in common\n",
    "comments = parser.find_all(\"span\", text=re.compile(\".*comments\"))\n",
    "\n",
    "# Get the parent post from the comment and scrape the data\n",
    "for comment in comments:\n",
    "    post = comment.parent.parent.parent.parent\n",
    "    # skip sponsored  or pinned content\n",
    "    if len(post.find_all(\"span\", text=\"promoted\")) > 0 \\\n",
    "        or len(post.find_all(\"span\", text=\"pinned by moderators\")):\n",
    "        continue\n",
    "    # get post data\n",
    "    post_data = {}\n",
    "    post_data[\"title\"] = post.find_all(\"h3\")[0].text\n",
    "    post_data[\"link\"] = post.find_all(\"h3\")[0].parent.parent[\"href\"]\n",
    "    post_data[\"age\"] =\" \".join(post.find_all(\"a\", text=re.compile(\".*ago\"))[0].text.split(\" \")[0:2])\n",
    "    post_data[\"comments\"] = post.find_all(\"span\", text=re.compile(\".*comments\"))[0].text.split(\" \")[0]\n",
    "    post_data[\"subreddit\"] = \"Main Page / \" + post.find_all(\"h3\")[0].parent.parent[\"href\"].split('/')[2]\n",
    "    posts.append(post_data)\n",
    "\n",
    "# Let's print evidence that something is working\n",
    "for post in posts:\n",
    "    print(\"Title: \" + post[\"title\"][:80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total posts collected: 37\n"
     ]
    }
   ],
   "source": [
    "# Let's also scrape some of the more interesting subreddits\n",
    "subreddits = [\"science\", \"technology\", \"programming\", \"AskReddit\", \"news\"]\n",
    "\n",
    "# Get the parent post from the comment and scrape the data\n",
    "for reddit in subreddits:\n",
    "    # go to subreddit\n",
    "    url = \"http://reddit.com/r/\" + reddit\n",
    "    html = requests.get(url, headers=headers).text\n",
    "    parser = bs(html)\n",
    "    # get comments <span>\n",
    "    comments = parser.find_all(\"span\", text=re.compile(\".*comments\"))\n",
    "    # get parent post and scrape data\n",
    "    for comment in comments:\n",
    "        post = comment.parent.parent.parent.parent\n",
    "        # skip sponsored or pinned content\n",
    "        if len(post.find_all(\"span\", text=\"promoted\")) > 0 \\\n",
    "            or len(post.find_all(\"span\", text=\"pinned by moderators\")):\n",
    "            continue\n",
    "        # get post data\n",
    "        post_data = {}\n",
    "        post_data[\"title\"] = post.find_all(\"h3\")[0].text\n",
    "        post_data[\"link\"] = post.find_all(\"h3\")[0].parent.parent[\"href\"]\n",
    "        post_data[\"age\"] =\" \".join(post.find_all(\"a\", text=re.compile(\".*ago\"))[0].text.split(\" \")[0:2])\n",
    "        post_data[\"comments\"] = post.find_all(\"span\", text=re.compile(\".*comments\"))[0].text.split(\" \")[0]\n",
    "        post_data[\"subreddit\"] = post.find_all(\"h3\")[0].parent.parent[\"href\"].split('/')[2]\n",
    "        posts.append(post_data)\n",
    "\n",
    "print(\"Total posts collected: \" + str(len(posts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put all collected posts into MongoDB\n",
    "for post in posts:\n",
    "    collection.insert_one(post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Page / AskReddit\r\n",
      "What was the very first movie to make you cry?\r\n",
      "\n",
      "Main Page / PublicFreakout\r\n",
      "Wild Karen loses mind over car on crosswalk\r\n",
      "\n",
      "Main Page / news\r\n",
      "Texas park ranger pushed into water after reminding crowd about social distancing\r\n",
      "\n",
      "Main Page / woahdude\r\n",
      "I made a big flip book during quarantine. My love to everyone who is struggling right now!\r\n",
      "\n",
      "Main Page / nextfuckinglevel\r\n",
      "I made a really big flip book during quarantine and people said to post it here. My love to everyone who is struggling right now!\r\n",
      "\n",
      "Main Page / coolguides\r\n",
      "A guide to mattress dimensions and bed sizes\r\n",
      "\n",
      "Main Page / politics\r\n",
      "One Death Is a Tragedy. 60,000 Deaths Are a Great Success. Most presidents try to console the nation in moments of grief, but Donald Trump is taking a victory lap.\r\n",
      "\n",
      "science\r\n",
      "Green method could enable hospitals to produce hydrogen peroxide in house. A team of researchers has developed a portable, more environmentally friendly method to produce hydrogen peroxide. It could enable hospitals to make their own supply of the disinfectant on demand and at lower cost.\r\n",
      "\n",
      "science\r\n",
      "New research provides evidence that men tend to mellow out when they are with their girlfriend. The study, published in Journal of Social and Personal Relationships, found that the presence of a romantic partner reduces risk-taking propensity in young men\r\n",
      "\n",
      "science\r\n",
      "Researchers invent a 3D print resin which can expand up to 40x after printing and produce objects larger than the printer's build volume\r\n",
      "\n",
      "science\r\n",
      "Nearly 15,000 Miles of New Roads Will Be Built in Tiger Habitat by 2050, Study Finds. 83,300 miles of roads that already cross through tiger habitat are decreasing the population and its prey by as much as 20 percent.\r\n",
      "\n",
      "science\r\n",
      "Children who have difficult relationships with their mothers are clingy towards their early teachers according to new study based on the NICHD Study of Early Child Care and Youth Development.\r\n",
      "\n",
      "science\r\n",
      "Young offenders who are sent to more rehabilitative youth facilities become less likely to reoffend than youngsters who are sent to harsher youth facilities. The latter are 27% more likely to recidivate in the eight years subsequent to their custody.\r\n",
      "\n",
      "science\r\n",
      "New research in Science reveals that SARSCoV2 can infect and replicate in cells that line the human intestine, helping to explain why some COVID19 patients experience gastrointestinal symptoms.\r\n",
      "\n",
      "technology\r\n",
      "Prisons Replace Ankle Bracelets With An Expensive Smartphone App That Doesn't Work\r\n",
      "\n",
      "technology\r\n",
      "Judge orders FCC to hand over IP addresses linked to fake net neutrality comments.\r\n",
      "\n",
      "technology\r\n",
      "Comcast Graciously Extends Suspension Of Completely Unnecessary Data Caps\r\n",
      "\n",
      "technology\r\n",
      "Did you know: Android was originally designed for digital cameras not phones\r\n",
      "\n",
      "technology\r\n",
      "India makes government tracing app mandatory for all workers\r\n",
      "\n",
      "programming\r\n",
      "Scott Hanselmann: \"Don’t feel you need to work more than 8 hours a day. Or 6. Don’t make code your hobby UNLESS YOU WANT TO\"\r\n",
      "\n",
      "programming\r\n",
      "I shipped a word processor that formatted the hard drive every 1024 saves.\r\n",
      "\n",
      "programming\r\n",
      "John Carmack: “Very early C compilers had all struct members in the same namespace, so you had to add prefixes like 'tc_size', 'ws_size', etc. Nowadays, there may be a dozen different 'size' members in a codebase. It is conceivable that understandability is actually lower with overloaded names.”\r\n",
      "\n",
      "programming\r\n",
      "JetBrains Academy for learning code launches for free during COVID-19 pandemic\r\n",
      "\n",
      "programming\r\n",
      "Cracking Age of Empires III over shader quality setting - a story or disassembly and debugging\r\n",
      "\n",
      "programming\r\n",
      "Getting started in Competitive Programming\r\n",
      "\n",
      "AskReddit\r\n",
      "What is something that is expensive, but only owned by poor people?\r\n",
      "\n",
      "AskReddit\r\n",
      "What was the very first movie to make you cry?\r\n",
      "\n",
      "AskReddit\r\n",
      "If Weak Sauce was a product, what would it taste like?\r\n",
      "\n",
      "AskReddit\r\n",
      "Who is the stranger that you have only seen/meet once in your life that you still think about time to time?\r\n",
      "\n",
      "AskReddit\r\n",
      "You wake up to a character customisation screen, what do you do to yourself?\r\n",
      "\n",
      "AskReddit\r\n",
      "People who decide to mow their laws before 9am, why do you do this?\r\n",
      "\n",
      "news\r\n",
      "Texas park ranger pushed into water after reminding crowd about social distancing\r\n",
      "\n",
      "news\r\n",
      "Police arrest 3 protesters, cite another 5 at ‘reopen Hawaii’ rally in front of State Capitol\r\n",
      "\n",
      "news\r\n",
      "Thousands of protesters flock to Huntington Beach following state-ordered Orange County beach closures\r\n",
      "\n",
      "news\r\n",
      "Colorado temporarily suspends evictions during pandemic\r\n",
      "\n",
      "news\r\n",
      "California prosecutors warn of release of 7 'high risk' sex offenders, some who served 'just days'\r\n",
      "\n",
      "news\r\n",
      "Huge amount of prime land returns to Australian hands after sale by Chinese billionaire.\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let print the titles, since that's all anyone reads anyways\n",
    "x = collection.find()\n",
    "for z in x:\n",
    "    print(z[\"subreddit\"] + \"\\r\\n\" + z[\"title\"] + \"\\r\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close database connection\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Iris Flower Dataset (API to SQL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source scikit-learn\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n"
     ]
    }
   ],
   "source": [
    "# What is the Iris database?\n",
    "print(\"Description\" + \"\\n\".join(iris.DESCR.split(\"\\n\")[35:46]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]]\n"
     ]
    }
   ],
   "source": [
    "# What data does it contain?\n",
    "print(iris.feature_names)\n",
    "print(iris.data[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor' 'virginica']\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "# Each row corresponds to an iris flower species\n",
    "print(iris.target_names)\n",
    "print(list(iris.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the data\n",
    "header = np.append(iris.feature_names, \"target\")\n",
    "table = np.append(iris.data, [[iris.target_names[target]] for target in iris.target], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DROP TABLE IF EXISTS IRIS;\n",
      "CREATE TABLE IRIS (\n",
      "  SEPAL_LENGTH FLOAT,\n",
      "  SEPAL_WIDTH FLOAT,\n",
      "  PETAL_LENGTH FLOAT,\n",
      "  PETAL_WIDTH FLOAT,\n",
      "  TARGET ENUM('setosa', 'versicolor', 'virginica')\n",
      ");\n",
      "\n",
      "INSERT INTO IRIS (SEPAL_LENGTH, SEPAL_WIDTH, PETAL_LENGTH, PETAL_WIDTH, TARGET)\n",
      "  VALUES ('5.1', '3.5', '1.4', '0.2', 'setosa');\n",
      "INSERT INTO IRIS (SEPAL_LENGTH, SEPAL_WIDTH, PETAL_LENGTH, PETAL_WIDTH, TARGET)\n",
      "  VALUES ('4.9', '3.0', '1.4', '0.2', 'setosa');\n",
      "INSERT INTO IRIS (SEPAL_LENGTH, SEPAL_WIDTH, PETAL_LENGTH, PETAL_WIDTH, TARGET)\n",
      "  VALUES ('4.7', '3.2', '1.3', '0.2', 'setosa');\n",
      "INSERT INTO IRIS (SEPAL_LENGTH, SEPAL_WIDTH, PETAL_LENGTH, PETAL_WIDTH, TARGET)\n",
      "  VALUES ('4.6', '3.1', '1.5', '0.2', 'setosa');\n",
      "INSERT INTO IRIS (SEPAL_LENGTH, SEPAL_WIDTH, PETAL_LENGTH, PETAL_WIDTH, TARGET)\n",
      "  VALUES ('5.0', '3.6', '1.4', '0.2', 'setosa');\n"
     ]
    }
   ],
   "source": [
    "# Destination SQL Script\n",
    "f = open(\"iris.sql\", \"w\")\n",
    "\n",
    "# Create table\n",
    "print(\"DROP TABLE IF EXISTS IRIS;\")\n",
    "print(\"CREATE TABLE IRIS (\")\n",
    "print(\"  SEPAL_LENGTH FLOAT,\")\n",
    "print(\"  SEPAL_WIDTH FLOAT,\")\n",
    "print(\"  PETAL_LENGTH FLOAT,\")\n",
    "print(\"  PETAL_WIDTH FLOAT,\")\n",
    "print(\"  TARGET ENUM(\" + str(list(iris.target_names))[1:-1] + \")\")\n",
    "print(\");\")\n",
    "\n",
    "f.write(\"DROP TABLE IF EXISTS IRIS;\\n\")\n",
    "f.write(\"CREATE TABLE IRIS (\\n\")\n",
    "f.write(\"  SEPAL_LENGTH FLOAT,\\n\")\n",
    "f.write(\"  SEPAL_WIDTH FLOAT,\\n\")\n",
    "f.write(\"  PETAL_LENGTH FLOAT,\\n\")\n",
    "f.write(\"  PETAL_WIDTH FLOAT,\\n\")\n",
    "f.write(\"  TARGET ENUM(\" + str(list(iris.target_names))[1:-1] + \")\\n\")\n",
    "f.write(\");\\n\")\n",
    "\n",
    "print()\n",
    "f.write(\"\\n\")\n",
    "\n",
    "# Insert data\n",
    "for row in table[0:5]:\n",
    "    print(\"INSERT INTO IRIS (SEPAL_LENGTH, SEPAL_WIDTH, PETAL_LENGTH, PETAL_WIDTH, TARGET)\")\n",
    "    print(\"  VALUES ('\" + \"', '\".join(row) + \"');\")\n",
    "\n",
    "for row in table:\n",
    "    f.write(\"INSERT INTO IRIS (SEPAL_LENGTH, SEPAL_WIDTH, PETAL_LENGTH, PETAL_WIDTH, TARGET)\\n\")\n",
    "    f.write(\"  VALUES ('\" + \"', '\".join(row) + \"');\\n\")\n",
    "\n",
    "# Close SQL Script\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
